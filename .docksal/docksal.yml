# Docker and Docker Compose based environment for Drupal.
# See https://github.com/docksal/docksal for more information and documentation.

# This is a shared configuration file that is intended to be stored in the project repo.
# For local overrides:
# - create .docksal/docksal-local.yml file and put local docker-compose configuration overrides there
# - add .docksal/docksal-local.yml to .gitignore

# Docksal stiches several docker-compose configuration files together.
# Run "fin config" to see which files are involved and the resulting configration.

version: "2.1"

services:

  elastic:
    image: docker.elastic.co/elasticsearch/elasticsearch:5.4.0
    mem_limit: 3g
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    labels:
      - io.docksal.virtual-host=elastic.${VIRTUAL_HOST}
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - esdata1:/usr/share/elasticsearch/data

  # CLI
  # Used for all python commandline tools that are not necessary for the actual scrapy container that may not exist on the host machine.
  python_container:
    hostname: python_container
    image: python
    volumes:
      # Project root volume
      - project_root:/var/www:rw,nocopy
      # Shared ssh-agent socket
      - docksal_ssh_agent:/.ssh-agent:ro
    stdin_open: true
    tty: true
    working_dir: '/var/www/portia_projects/hoaxlyPortia'
    command: [ "/bin/bash" ]
    environment:
      - HOST_UID
      - HOST_GID
      - DOCROOT
      - XDEBUG_ENABLED=${XDEBUG_ENABLED:-0}
    dns:
      - ${DOCKSAL_DNS1}
      - ${DOCKSAL_DNS2}


  # demo elasticsearch frontend php search interface
  # web:
  #   image: registry.acolono.net:444/hoaxly/hoaxly-vanillasearch-nginx
  #   ports:
  #     - "8080:80"
  #   labels:
  #     - io.docksal.virtual-host=search.${VIRTUAL_HOST}
  #     - io.docksal.project-root=${PROJECT_ROOT}
  #   depends_on:
  #     - php
  #   environment:
  #     - APP_ES_HOST=elastic
  #     - APP_ES_PORT=9200
  #     - APP_LOG_FILE=/vanillasearch.log

  # php:
  #   image: registry.acolono.net:444/hoaxly/hoaxly-vanillaphp:latest


  # inspect index with this container once you have data in elasticsearch
  # kibana:
  #   image: docker.elastic.co/kibana/kibana:5.4.0
  #   mem_limit: 1024m
  #   ports:
  #     - "5601:5601"
  #   depends_on:
  #     - elastic
  #   environment:
  #     - ELASTICSEARCH_URL=http://elastic:9200


# enable this container to build new spiders
  portia:
    image: registry.acolono.net:444/hoaxly/hoaxly
    build: ${PROJECT_ROOT}
    container_name: portia
    #restart: always
    tty: true
    mem_limit: 1024m
    ports:
      - "9001:9001"
      - "6800:6800"
    labels:
      - io.docksal.virtual-host=portia.${VIRTUAL_HOST}
    volumes:
      #- ${PROJECT_ROOT}/config/scrapyd.conf:/etc/scrapyd/scrapyd.conf
      - ${PROJECT_ROOT}/data/slyd:/app/slyd/data
      - ${PROJECT_ROOT}/data/scrapyd:/var/lib/scrapyd
      - ${PROJECT_ROOT}/portia_projects:/app/data/projects:rw
      #- ${PROJECT_ROOT}/portia_projects/packages:/app/data/packages:rw
      - ${PROJECT_ROOT}/example-output:/app/data/example-output:rw
      #- ${PROJECT_ROOT}/config/local_slybot_settings.py:/app/slyd/slybot/slybot/local_slybot_settings.py
      #- ${PROJECT_ROOT}/portia_projects/hoaxlyPortia/spiders/settings.py:/app/slyd/slybot/slybot/settings.py
      #- ${PROJECT_ROOT}/portia_projects/hoaxlyPortia/spiders/mypipelines.py:/app/slyd/slybot/slybot/mypipelines.py
      #- ${PROJECT_ROOT}/portia_projects/hoaxlyPortia/spiders/mymiddleware.py:/app/slyd/slybot/slybot/mymiddleware.py




volumes:
  esdata1:
    driver: local
